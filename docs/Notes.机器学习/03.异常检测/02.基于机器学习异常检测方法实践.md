---
title: 基于机器学习异常检测方法实践
date: 2022-03-03 13:17:14
permalink: /pages/32d82b/
category:
  - 机器学习
  - 异常检测
tag:
  - 
---

#  机器学习实践：基于机器学习算法的时间序列价格异常检测

[[TOC]]

异常检测是指检测数据集里面与其他数据不相符的数据点。

异常检测也称为异常值检测，是一种数据挖掘过程，用于确定数据集中发现的异常类型并确定其出现的详细信息。 **在当今世界，由于大量数据无法手动标记异常值，自动异常检测显得至关重要**。 自动异常检测具有广泛的应用，例如欺诈检测，系统健康监测，故障检测以及传感器网络中的事件检测系统等。

你是否有过这样的经历，比如，你经常前往某个目的地进行商务旅行，并且你总是住在同一家酒店。虽然大部分时间那里的房价几乎总是相似的，但偶尔相同的酒店，相同的房间类型，费率却高得令人无法接受，以致于你必须换到另一家酒店，因为你的旅行补贴不能包含这么高的价格。我经历了好几次这样的事情，这让我想到，如果我们能够创建一个模型来自动检测这种价格异常会怎么样呢？

当然某些情况下，一些异常在我们这一生中也只会发生一次，并且我们会事先知道它们的发生，还知道在未来每年的相同时间几乎不会再发生，例如2019年2月2日至2月4日亚特兰大荒谬的酒店价格（译者注：2019年2月3日，第53届超级碗比赛在亚特兰大梅赛德斯——奔驰体育场举行）。

在这篇文章中，我们将探讨不同的异常检测技术，我们的目标是在无监督学习的情况下考察酒店房间价格的时间序列中所在的异常。让我们开始吧！

## **数据获取**

事实上要获取全部数据非常困难，我只能得到一些不完美的数据。

```python
import pandas as pd
import numpy as np
import matplotlib.dates as md
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import host_subplot
import mpl_toolkits.axisartist as AA
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.covariance import EllipticEnvelope
from pyemma import msm
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from mpl_toolkits.mplot3d import Axes3D
from pyemma import msm
%matplotlib inline
```

我们将使用的数据是Personalize Expedia Hotel Searches数据集的子集，读者可在此处找到（*https://www.kaggle.com/c/expedia-personalized-sort/data*，其中训练集为train.csv，测试集为test.csv）。

我们打算按如下方式对训练集train.csv的一个子集进行剪切：

- 选择包含数据点最多的一个酒店property_id = 104517。

- 选择visitor_location_country_id = 219 ，国家ID 219是指美国。 我们这样做是为了统一price_usd列。由于不同国家在显示税费方面有不同的惯例，所以此列的价格可能是每晚或整个住宿的。而我们知道此列向美国游客展示的价格总是每晚不含税的。

- 选择search_room_count = 1。

- 选择我们需要的特征：date_time，price_usd，srch_booking_window，srch_saturday_night_bool。

```python
expedia = pd.read_csv('expedia_train.csv')
df = expedia.loc[expedia['prop_id'] == 104517]
df = df.loc[df['srch_room_count'] == 1]
df = df.loc[df['visitor_location_country_id'] == 219]
df = df[['date_time', 'price_usd', 'srch_booking_window', 'srch_saturday_night_bool']]
```

进行数据剪切后，我们将要适用的数据如下：

```python
df.info()
```

![image-20201023165336899](http://minio.vancode.top/vancode/algorithm/ad/image-20201023165336899.png)

 

```python
df['price_usd'].describe()
```


至此，我们已经检测到一个极端异常，即最大price_usd是5584美元。

如果某单一数据点可被视为相应于其余数据的异常，我们则称之为**Point Anomalies**（例如，购买具有大的交易价值的物品）。我们可以回去检查搜索日志，看看它是什么。 经过一番调查后，我猜它要么是一个错误要么是用户偶然搜索了一个总统套房而无意预订或查看。为了找到更多不是极端的异常，决定删除这个点。



```python
expedia.loc[(expedia['price_usd'] == 5584) &
(expedia['visitor_location_country_id'] == 219)]
```

```python
df = df.loc[df['price_usd'] < 5584]
```



至此，我相信你已经发现我们遗漏了一些东西，也就是说，我们不知道用户搜索的房间类型，标准间的价格可能与大床海景房的价格有很大差异。请记住这一点，但为了示范目的，我们不得不继续。

## **时间序列可视化**





```python
df.plot(x='date_time', y='price_usd', figsize=(12,6))
plt.xlabel('Date time')
plt.ylabel('Price in USD')
plt.title('Time Series of room price by date time of search');
```

![img](http://minio.vancode.top/vancode/algorithm/ad/image-20201023171711751.png)



```python
a = df.loc[df['srch_saturday_night_bool'] == 0, 'price_usd']
b = df.loc[df['srch_saturday_night_bool'] == 1, 'price_usd']
plt.figure(figsize=(10, 6))
plt.hist(a, bins = 50, alpha=0.5, label='Search Non-Sat Night')
plt.hist(b, bins = 50, alpha=0.5, label='Search Sat Night')
plt.legend(loc='upper right')
plt.xlabel('Price')
plt.ylabel('Count')
plt.show()
```

![image-20201023172411751](http://minio.vancode.top/vancode/algorithm/ad/image-20201023172411751.png)一般来说，搜索非周六晚上的价格会更稳定且更低，而周六晚上的价格通常会上涨，看来这家酒店在周末很受欢迎。

## **基于聚类算法的异常检测**

### **k-means 算法**

[k-means](#1.4.1 k-means聚类)是一种应用广泛的聚类算法。它创建了k个类似的数据点集（即聚类），不属于这些组的数据可能会被标记为异常。

#### **1 簇数量选择--Elbow方法**

在我们开始应用k-means算法之前，先使用elbow方法来确定最佳聚类数。

```python
data = df[['price_usd', 'srch_booking_window', 'srch_saturday_night_bool']]
n_cluster = range(1, 20)
kmeans = [KMeans(n_clusters=i).fit(data) for i in n_cluster]
scores = [kmeans[i].score(data) for i in range(len(kmeans))]
fig, ax = plt.subplots(figsize=(10,6))
ax.plot(n_cluster, scores)
plt.xlabel('Number of Clusters')
plt.ylabel('Score')
plt.title('Elbow Curve')
plt.show()
```

![ElbowMethod](http://minio.vancode.top/vancode/algorithm/ad/ElbowMethod.png)

上图曲线中，我们可以看到，图形在聚类簇数目在10之后趋于平稳，这意味着添加更多的簇并不能解释我们相关变量中的更多方差。

#### **2 3D聚类图**

设置$n\_clusters=10 $,并将k-means的输出数据绘制成3D聚类图。

```python
X = df[['price_usd', 'srch_booking_window', 'srch_saturday_night_bool']]
X = X.reset_index(drop=True)
km = KMeans(n_clusters=10)
km.fit(X)
km.predict(X)
labels = km.labels_
#Plotting
fig = plt.figure(1, figsize=(7,7))
ax = Axes3D(fig, rect=[0, 0, 0.95, 1], elev=48, azim=134)
ax.scatter(X.iloc[:,0], X.iloc[:,1], X.iloc[:,2],
         c=labels.astype(np.float), edgecolor="k")
ax.set_xlabel("price_usd")
ax.set_ylabel("srch_booking_window")
ax.set_zlabel("srch_saturday_night_bool")
plt.title("K Means", fontsize=14)
```



![3D_graph_K-means](http://minio.vancode.top/vancode/algorithm/ad/3D_graph_K-means.png)

#### **3  PCA(Principal component analysis，主成分分析)**

使用PCA(Principal component analysis，主成分分析)算法确定保留多少个特征是最合适的。

```python
data = df[['price_usd', 'srch_booking_window', 'srch_saturday_night_bool']]
X = data.values
# Standard
# 不仅计算训练数据的均值和方差，还会基于计算出来的均值和方差来转换训练数据，
# 从而把数据转换成标准的正太分布
X_std = StandardScaler().fit_transform(X)




# 计算协方差矩阵的特征向量和特征值
mean_vec = np.mean(X_std, axis=0)
cov_mat = np.cov(X_std.T)
eig_vals, eig_vecs = np.linalg.eig(cov_mat)

# Create a list of (eigenvalue, eigenvector) tuples
eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:, i])
             for i in range(len(eig_vals))]
eig_pairs.sort(key=lambda x: x[0], reverse=True)

# 计算特征值的解释方差
tot = sum(eig_vals)
# Individual explained variance
var_exp = [(i/tot)*100 for i in sorted(eig_vals, reverse=True)]

cum_var_exp = np.cumsum(var_exp)  # Cumulative explained variance
# plotting
# plt.figure(figsize=(10, 5))
# plt.bar(range(len(var_exp)), var_exp, alpha=0.3, align='center', label='individual explained variance', color = 'g')
# plt.step(range(len(cum_var_exp)), cum_var_exp, where='mid',label='cumulative explained variance')
# plt.ylabel('Explained variance ratio')
# plt.xlabel('Principal components')
# plt.legend(loc='best')
# plt.show()

```

![PCA](http://minio.vancode.top/vancode/algorithm/ad/PCA.png)

#### **4 特征选择**

```python
# Take useful feature and standardize them
data = df[['price_usd', 'srch_booking_window', 'srch_saturday_night_bool']]
X_std = StandardScaler().fit_transform(X)
data = pd.DataFrame(X_std)
# reduce to 2 important features
pca = PCA(n_components=2)
data = pca.fit_transform(data)
# standardize these 2 new features
scaler = StandardScaler()
np_scaled = scaler.fit_transform(data)
data = pd.DataFrame(np_scaled)


```

```python
kmeans = [KMeans(n_clusters=i).fit(data) for i in n_cluster]
df['cluster'] = kmeans[9].predict(data)
df.index = data.index
df['principal_feature1'] = data[0]
df['principal_feature2'] = data[1]
df['cluster'].value_counts()



outliers_fraction = 0.01
data = data.reset_index(drop=True)
# get the distance between each point and its nearest centroid. The biggest distances are considered as anomaly
distance = getDistanceByPoint(data, kmeans[9])
distance = distance.reset_index(drop=True)
number_of_outliers = int(outliers_fraction*len(distance))
threshold = distance.nlargest(number_of_outliers).min()
# anomaly1 contain the anomaly result of the above method Cluster (0:normal, 1:anomaly)


```

#### **5 可视化异常集群视图**

```python
#可视化异常集群视图 visualisation of anomaly with cluster view
fig, ax = plt.subplots(figsize=(10, 6))
colors = {0: 'blue', 1: 'red'}
ax.scatter(df['principal_feature1'], df['principal_feature2'],
           c=df["anomaly1"].apply(lambda x: colors[x]))
plt.xlabel('principal feature1')
plt.ylabel('principal feature2')
plt.show()

```

![anomaly_with_cluster_view](http://minio.vancode.top/vancode/algorithm/ad/cluster_anomaly_view1.png)

#### **6 时间序列可视化**

```python
df = df.sort_values('date_time')
df['date_time_int'] = df.date_time.astype(np.int64)
fig, ax = plt.subplots(figsize=(10,6))
a = df.loc[df['anomaly1'] == 1, ['date_time_int', 'price_usd']] #anomaly
ax.plot(df['date_time_int'], df['price_usd'], color='blue', label='Normal')
ax.scatter(a['date_time_int'],a['price_usd'], color='red', label='Anomaly')
plt.xlabel('Date Time Integer')
plt.ylabel('price in USD')
plt.legend()
plt.show();
```

![time_series_view](http://minio.vancode.top/vancode/algorithm/ad/cluster_ts_view1.png)

#### **7 直方图可视化**

```python
a = df.loc[df['anomaly2'] == 1, 'price_usd']
b = df.loc[df['anomaly2'] == -1, 'price_usd']

fig, axs = plt.subplots(figsize=(10,6))
axs.hist([a,b], bins=32, stacked=True, color=['blue', 'red'])
plt.show()
```

![cluster_hist_view1](http://minio.vancode.top/vancode/algorithm/ad/cluster_hist_view1.png)

## 基于孤立森林算法的异常检测

#### **1 iforest 算法**

```python
data = df[['price_usd', 'srch_booking_window', 'srch_saturday_night_bool']]
scaler = StandardScaler()
np_scaled = scaler.fit_transform(data)
data = pd.DataFrame(np_scaled)
# train isolation forest
model =  IsolationForest(contamination=outliers_fraction)
model.fit(data)

df['anomaly2'] = pd.Series(model.predict(data))
# df['anomaly2'] = df['anomaly2'].map( {1: 0, -1: 1} )

```

#### **2 时序图**

```python
#plotting
fig, ax = plt.subplots(figsize=(10,6))
a = df.loc[df['anomaly2'] == -1, ['date_time_int', 'price_usd']] #anomaly
ax.plot(df['date_time_int'], df['price_usd'], color='blue', label = 'Normal')
ax.scatter(a['date_time_int'],a['price_usd'], color='red', label = 'Anomaly')
plt.legend()
plt.show()

```

![iforest](http://minio.vancode.top/vancode/algorithm/ad/iforest_ts_view.png)

#### **3 直方图**

```python
a = df.loc[df['anomaly2'] == 1, 'price_usd']
b = df.loc[df['anomaly2'] == -1, 'price_usd']
fig, axs = plt.subplots(figsize=(10,6))
axs.hist([a,b], bins=32, stacked=True, color=['blue', 'red'])
plt.show()
```

![iforest_hits_view](http://minio.vancode.top/vancode/algorithm/ad/iforest_hist_view.png)

## 基于支持向量机算法的异常检测

#### **1 SVM 算法**

```python
data = df[['price_usd', 'srch_booking_window', 'srch_saturday_night_bool']]
scaler = StandardScaler()
np_scaled = scaler.fit_transform(data)
data = pd.DataFrame(np_scaled)
# train oneclassSVM 
model = OneClassSVM(nu=outliers_fraction, kernel="rbf", gamma=0.01)
model.fit(data)
 
df['anomaly3'] = pd.Series(model.predict(data))
# df['anomaly3'] = df['anomaly3'].map( {1: 0, -1: 1} )

```

#### **2 时序图**

```python
fig, ax = plt.subplots(figsize=(10,6))
a = df.loc[df['anomaly3'] == -1, ['date_time_int', 'price_usd']] #anomaly
ax.plot(df['date_time_int'], df['price_usd'], color='blue', label ='Normal')
ax.scatter(a['date_time_int'],a['price_usd'], color='red', label = 'Anomaly')
plt.legend()
plt.show();
```

![svm_ts_view](http://minio.vancode.top/vancode/algorithm/ad/svm_ts_view.png)

#### **3 直方图**

```python
a = df.loc[df['anomaly3'] == 1, 'price_usd']
b = df.loc[df['anomaly3'] == -1, 'price_usd']

fig, axs = plt.subplots(figsize=(10,6))
axs.hist([a,b], bins=32, stacked=True, color=['blue', 'red'])
plt.show();
```

![svm_hits_view](http://minio.vancode.top/vancode/algorithm/ad/svm_hist_view.png)

## 基于高斯分布的异常检测

#### 1 直方图

```python
df_class0 = df.loc[df['srch_saturday_night_bool'] == 0, 'price_usd']
df_class1 = df.loc[df['srch_saturday_night_bool'] == 1, 'price_usd']

fig, axs = plt.subplots(1,2)
df_class0.hist(ax=axs[0], bins=30)
df_class1.hist(ax=axs[1], bins=30);
```

![GD_hits_view](http://minio.vancode.top/vancode/algorithm/ad/GD_hist_view.png)

#### 2 高斯

```python
envelope =  EllipticEnvelope(contamination = outliers_fraction) 
X_train = df_class0.values.reshape(-1,1)
envelope.fit(X_train)
df_class0 = pd.DataFrame(df_class0)
df_class0['deviation'] = envelope.decision_function(X_train)
df_class0['anomaly'] = envelope.predict(X_train)

envelope =  EllipticEnvelope(contamination = outliers_fraction) 
X_train = df_class1.values.reshape(-1,1)
envelope.fit(X_train)
df_class1 = pd.DataFrame(df_class1)
df_class1['deviation'] = envelope.decision_function(X_train)
df_class1['anomaly'] = envelope.predict(X_train)
a0 = df_class0.loc[df_class0['anomaly'] == 1, 'price_usd']
b0 = df_class0.loc[df_class0['anomaly'] == -1, 'price_usd']

a2 = df_class1.loc[df_class1['anomaly'] == 1, 'price_usd']
b2 = df_class1.loc[df_class1['anomaly'] == -1, 'price_usd']

#Gaussian Distribution Anomaly Detection
'''
fig, axs = plt.subplots(1,2)
axs[0].hist([a0,b0], bins=32, stacked=True, color=['blue', 'red'])
axs[1].hist([a2,b2], bins=32, stacked=True, color=['blue', 'red'])
axs[0].set_title("Search Non Saturday Night")
axs[1].set_title("Search Saturday Night")
plt.show()
```



![GD_anomaly_view](http://minio.vancode.top/vancode/algorithm/ad/GD_anomaly_view.png)

## **马尔可夫链的异常检测**

